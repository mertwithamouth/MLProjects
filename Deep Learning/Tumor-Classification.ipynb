{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,explained_variance_score\n",
    "from tensorflow.keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"DATA/cancer_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "0                  0.2654          0.4601                  0.11890   \n",
       "1                  0.1860          0.2750                  0.08902   \n",
       "2                  0.2430          0.3613                  0.08758   \n",
       "3                  0.2575          0.6638                  0.17300   \n",
       "4                  0.1625          0.2364                  0.07678   \n",
       "..                    ...             ...                      ...   \n",
       "564                0.2216          0.2060                  0.07115   \n",
       "565                0.1628          0.2572                  0.06637   \n",
       "566                0.1418          0.2218                  0.07820   \n",
       "567                0.2650          0.4087                  0.12400   \n",
       "568                0.0000          0.2871                  0.07039   \n",
       "\n",
       "     benign_0__mal_1  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "..               ...  \n",
       "564                0  \n",
       "565                0  \n",
       "566                0  \n",
       "567                0  \n",
       "568                1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='benign_0__mal_1', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"benign_0__mal_1\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst concave points      -0.793566\n",
       "worst perimeter           -0.782914\n",
       "mean concave points       -0.776614\n",
       "worst radius              -0.776454\n",
       "mean perimeter            -0.742636\n",
       "worst area                -0.733825\n",
       "mean radius               -0.730029\n",
       "mean area                 -0.708984\n",
       "mean concavity            -0.696360\n",
       "worst concavity           -0.659610\n",
       "mean compactness          -0.596534\n",
       "worst compactness         -0.590998\n",
       "radius error              -0.567134\n",
       "perimeter error           -0.556141\n",
       "area error                -0.548236\n",
       "worst texture             -0.456903\n",
       "worst smoothness          -0.421465\n",
       "worst symmetry            -0.416294\n",
       "mean texture              -0.415185\n",
       "concave points error      -0.408042\n",
       "mean smoothness           -0.358560\n",
       "mean symmetry             -0.330499\n",
       "worst fractal dimension   -0.323872\n",
       "compactness error         -0.292999\n",
       "concavity error           -0.253730\n",
       "fractal dimension error   -0.077972\n",
       "symmetry error             0.006522\n",
       "texture error              0.008303\n",
       "mean fractal dimension     0.012838\n",
       "smoothness error           0.067016\n",
       "benign_0__mal_1            1.000000\n",
       "Name: benign_0__mal_1, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['benign_0__mal_1'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"benign_0__mal_1\",axis=1).values\n",
    "y=df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)-1\n",
    "#number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop =EarlyStopping(monitor='val_loss', mode=\"min\",\n",
    "                        verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "\n",
    "model.add(Dense(30, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "\n",
    "#Binary Classification\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.6799 - val_loss: 0.6686\n",
      "Epoch 2/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6687 - val_loss: 0.6590\n",
      "Epoch 3/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6592 - val_loss: 0.6491\n",
      "Epoch 4/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6464 - val_loss: 0.6390\n",
      "Epoch 5/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6374 - val_loss: 0.6284\n",
      "Epoch 6/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6287 - val_loss: 0.6163\n",
      "Epoch 7/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6157 - val_loss: 0.6028\n",
      "Epoch 8/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6015 - val_loss: 0.5875\n",
      "Epoch 9/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5889 - val_loss: 0.5717\n",
      "Epoch 10/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5732 - val_loss: 0.5552\n",
      "Epoch 11/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5566 - val_loss: 0.5376\n",
      "Epoch 12/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5397 - val_loss: 0.5201\n",
      "Epoch 13/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5163 - val_loss: 0.5022\n",
      "Epoch 14/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5006 - val_loss: 0.4840\n",
      "Epoch 15/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4860 - val_loss: 0.4647\n",
      "Epoch 16/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4645 - val_loss: 0.4453\n",
      "Epoch 17/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4477 - val_loss: 0.4263\n",
      "Epoch 18/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4350 - val_loss: 0.4078\n",
      "Epoch 19/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4149 - val_loss: 0.3897\n",
      "Epoch 20/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3940 - val_loss: 0.3731\n",
      "Epoch 21/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3863 - val_loss: 0.3580\n",
      "Epoch 22/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3620 - val_loss: 0.3424\n",
      "Epoch 23/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3448 - val_loss: 0.3260\n",
      "Epoch 24/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3419 - val_loss: 0.3118\n",
      "Epoch 25/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3124 - val_loss: 0.2981\n",
      "Epoch 26/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3086 - val_loss: 0.2861\n",
      "Epoch 27/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2818 - val_loss: 0.2751\n",
      "Epoch 28/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2880 - val_loss: 0.2662\n",
      "Epoch 29/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2661 - val_loss: 0.2565\n",
      "Epoch 30/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2671 - val_loss: 0.2479\n",
      "Epoch 31/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2618 - val_loss: 0.2403\n",
      "Epoch 32/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2437 - val_loss: 0.2308\n",
      "Epoch 33/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2350 - val_loss: 0.2231\n",
      "Epoch 34/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2301 - val_loss: 0.2173\n",
      "Epoch 35/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2269 - val_loss: 0.2125\n",
      "Epoch 36/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2333 - val_loss: 0.2105\n",
      "Epoch 37/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2092 - val_loss: 0.2041\n",
      "Epoch 38/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2079 - val_loss: 0.1965\n",
      "Epoch 39/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2101 - val_loss: 0.1917\n",
      "Epoch 40/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1921 - val_loss: 0.1885\n",
      "Epoch 41/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1921 - val_loss: 0.1855\n",
      "Epoch 42/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1772 - val_loss: 0.1823\n",
      "Epoch 43/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1773 - val_loss: 0.1795\n",
      "Epoch 44/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1715 - val_loss: 0.1763\n",
      "Epoch 45/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1752 - val_loss: 0.1734\n",
      "Epoch 46/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1591 - val_loss: 0.1711\n",
      "Epoch 47/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1580 - val_loss: 0.1692\n",
      "Epoch 48/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1675 - val_loss: 0.1637\n",
      "Epoch 49/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1561 - val_loss: 0.1616\n",
      "Epoch 50/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1458 - val_loss: 0.1596\n",
      "Epoch 51/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1446 - val_loss: 0.1553\n",
      "Epoch 52/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1417 - val_loss: 0.1541\n",
      "Epoch 53/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1432 - val_loss: 0.1558\n",
      "Epoch 54/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1356 - val_loss: 0.1558\n",
      "Epoch 55/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1367 - val_loss: 0.1520\n",
      "Epoch 56/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1317 - val_loss: 0.1467\n",
      "Epoch 57/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1260 - val_loss: 0.1443\n",
      "Epoch 58/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1262 - val_loss: 0.1438\n",
      "Epoch 59/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1183 - val_loss: 0.1463\n",
      "Epoch 60/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1203 - val_loss: 0.1458\n",
      "Epoch 61/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1090 - val_loss: 0.1406\n",
      "Epoch 62/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1149 - val_loss: 0.1384\n",
      "Epoch 63/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1109 - val_loss: 0.1391\n",
      "Epoch 64/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1160 - val_loss: 0.1397\n",
      "Epoch 65/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1033 - val_loss: 0.1384\n",
      "Epoch 66/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1008 - val_loss: 0.1357\n",
      "Epoch 67/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0998 - val_loss: 0.1358\n",
      "Epoch 68/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1051 - val_loss: 0.1345\n",
      "Epoch 69/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1046 - val_loss: 0.1355\n",
      "Epoch 70/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0951 - val_loss: 0.1360\n",
      "Epoch 71/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0992 - val_loss: 0.1360\n",
      "Epoch 72/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0906 - val_loss: 0.1341\n",
      "Epoch 73/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0953 - val_loss: 0.1320\n",
      "Epoch 74/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0926 - val_loss: 0.1314\n",
      "Epoch 75/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1017 - val_loss: 0.1317\n",
      "Epoch 76/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0898 - val_loss: 0.1312\n",
      "Epoch 77/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0852 - val_loss: 0.1318\n",
      "Epoch 78/600\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0875 - val_loss: 0.1333\n",
      "Epoch 79/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0945 - val_loss: 0.1332\n",
      "Epoch 80/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0875 - val_loss: 0.1300\n",
      "Epoch 81/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0863 - val_loss: 0.1294\n",
      "Epoch 82/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0789 - val_loss: 0.1301\n",
      "Epoch 83/600\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0793 - val_loss: 0.1308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0779 - val_loss: 0.1308\n",
      "Epoch 85/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0791 - val_loss: 0.1329\n",
      "Epoch 86/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0823 - val_loss: 0.1325\n",
      "Epoch 87/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0857 - val_loss: 0.1297\n",
      "Epoch 88/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0796 - val_loss: 0.1268\n",
      "Epoch 89/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0755 - val_loss: 0.1304\n",
      "Epoch 90/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0765 - val_loss: 0.1351\n",
      "Epoch 91/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0752 - val_loss: 0.1342\n",
      "Epoch 92/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0811 - val_loss: 0.1280\n",
      "Epoch 93/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0759 - val_loss: 0.1256\n",
      "Epoch 94/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0800 - val_loss: 0.1273\n",
      "Epoch 95/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0746 - val_loss: 0.1281\n",
      "Epoch 96/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0733 - val_loss: 0.1307\n",
      "Epoch 97/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0730 - val_loss: 0.1312\n",
      "Epoch 98/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0686 - val_loss: 0.1288\n",
      "Epoch 99/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0753 - val_loss: 0.1288\n",
      "Epoch 100/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0647 - val_loss: 0.1282\n",
      "Epoch 101/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0695 - val_loss: 0.1284\n",
      "Epoch 102/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0708 - val_loss: 0.1287\n",
      "Epoch 103/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0760 - val_loss: 0.1267\n",
      "Epoch 104/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0718 - val_loss: 0.1263\n",
      "Epoch 105/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0678 - val_loss: 0.1254\n",
      "Epoch 106/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0622 - val_loss: 0.1270\n",
      "Epoch 107/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0601 - val_loss: 0.1304\n",
      "Epoch 108/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0726 - val_loss: 0.1322\n",
      "Epoch 109/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0679 - val_loss: 0.1268\n",
      "Epoch 110/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0763 - val_loss: 0.1252\n",
      "Epoch 111/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0676 - val_loss: 0.1251\n",
      "Epoch 112/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0728 - val_loss: 0.1274\n",
      "Epoch 113/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0651 - val_loss: 0.1319\n",
      "Epoch 114/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0625 - val_loss: 0.1303\n",
      "Epoch 115/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0636 - val_loss: 0.1302\n",
      "Epoch 116/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0661 - val_loss: 0.1296\n",
      "Epoch 117/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0615 - val_loss: 0.1270\n",
      "Epoch 118/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0598 - val_loss: 0.1291\n",
      "Epoch 119/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0644 - val_loss: 0.1301\n",
      "Epoch 120/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0615 - val_loss: 0.1264\n",
      "Epoch 121/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0561 - val_loss: 0.1267\n",
      "Epoch 122/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0703 - val_loss: 0.1265\n",
      "Epoch 123/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0658 - val_loss: 0.1296\n",
      "Epoch 124/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0612 - val_loss: 0.1341\n",
      "Epoch 125/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0657 - val_loss: 0.1309\n",
      "Epoch 126/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0533 - val_loss: 0.1279\n",
      "Epoch 127/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0607 - val_loss: 0.1263\n",
      "Epoch 128/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0733 - val_loss: 0.1303\n",
      "Epoch 129/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0661 - val_loss: 0.1337\n",
      "Epoch 130/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0619 - val_loss: 0.1295\n",
      "Epoch 131/600\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0566 - val_loss: 0.1267\n",
      "Epoch 132/600\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0612 - val_loss: 0.1286\n",
      "Epoch 133/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0604 - val_loss: 0.1286\n",
      "Epoch 134/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0587 - val_loss: 0.1269\n",
      "Epoch 135/600\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0580 - val_loss: 0.1297\n",
      "Epoch 136/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0542 - val_loss: 0.1322\n",
      "Epoch 00136: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf47aab190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,batch_size=128,\n",
    "         validation_data=(X_test,y_test),epochs=600,\n",
    "          callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(data=model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.677677</td>\n",
       "      <td>0.668620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.667073</td>\n",
       "      <td>0.659003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.649108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.647747</td>\n",
       "      <td>0.639026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.637325</td>\n",
       "      <td>0.628377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.059246</td>\n",
       "      <td>0.128555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.058553</td>\n",
       "      <td>0.128640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.058622</td>\n",
       "      <td>0.126913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.058168</td>\n",
       "      <td>0.129685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.057785</td>\n",
       "      <td>0.132201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.677677  0.668620\n",
       "1    0.667073  0.659003\n",
       "2    0.657469  0.649108\n",
       "3    0.647747  0.639026\n",
       "4    0.637325  0.628377\n",
       "..        ...       ...\n",
       "131  0.059246  0.128555\n",
       "132  0.058553  0.128640\n",
       "133  0.058622  0.126913\n",
       "134  0.058168  0.129685\n",
       "135  0.057785  0.132201\n",
       "\n",
       "[136 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.991954\n",
       "1      0.982576\n",
       "2      0.993890\n",
       "3      0.007174\n",
       "4      0.999357\n",
       "         ...   \n",
       "138    0.000292\n",
       "139    0.999997\n",
       "140    0.001093\n",
       "141    0.918612\n",
       "142    0.000150\n",
       "Length: 143, dtype: float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions=pd.Series(predictions.reshape(143,))\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Test Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Test Y\n",
       "0              1\n",
       "1              1\n",
       "2              1\n",
       "3              0\n",
       "4              1\n",
       "..           ...\n",
       "138            0\n",
       "139            1\n",
       "140            0\n",
       "141            1\n",
       "142            0\n",
       "\n",
       "[143 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame(y_test,columns=[\"True Test Y\"])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.concat([pred_df,test_predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.columns=[\"True Test Y\",\"Model Prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Test Y</th>\n",
       "      <th>Model Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.982576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>0.918612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Test Y  Model Prediction\n",
       "0              1          0.991954\n",
       "1              1          0.982576\n",
       "2              1          0.993890\n",
       "3              0          0.007174\n",
       "4              1          0.999357\n",
       "..           ...               ...\n",
       "138            0          0.000292\n",
       "139            1          0.999997\n",
       "140            0          0.001093\n",
       "141            1          0.918612\n",
       "142            0          0.000150\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round(x):\n",
    "    number_dec = float(str(x-int(x))[1:])\n",
    "    if number_dec>0.5:\n",
    "        return 1\n",
    "    elif number_dec==0.5:\n",
    "        return number_dec\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"Model Prediction\"]=pred_df[\"Model Prediction\"].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_data_num=len(pred_df[pred_df[\"True Test Y\"]==pred_df[\"Model Prediction\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.06291111964957226\n",
      "MSE: 0.026597924042063313\n",
      "RMSE: 0.1630886999214333\n",
      "VarScore: 0.8902241427192943\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_test, predictions))  \n",
    "print('MSE:', mean_squared_error(y_test, predictions))  \n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('VarScore:',explained_variance_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predict_class=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        55\n",
      "           1       0.99      0.97      0.98        88\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "\n",
    "model.add(Dense(30, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Binary Classification\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "4/4 [==============================] - 1s 43ms/step - loss: 0.7120 - val_loss: 0.6679\n",
      "Epoch 2/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6937 - val_loss: 0.6628\n",
      "Epoch 3/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6873 - val_loss: 0.6581\n",
      "Epoch 4/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6751 - val_loss: 0.6535\n",
      "Epoch 5/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6747 - val_loss: 0.6488\n",
      "Epoch 6/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6676 - val_loss: 0.6438\n",
      "Epoch 7/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6769 - val_loss: 0.6384\n",
      "Epoch 8/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6597 - val_loss: 0.6328\n",
      "Epoch 9/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6535 - val_loss: 0.6268\n",
      "Epoch 10/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6584 - val_loss: 0.6210\n",
      "Epoch 11/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6357 - val_loss: 0.6152\n",
      "Epoch 12/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6257 - val_loss: 0.6084\n",
      "Epoch 13/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6267 - val_loss: 0.6004\n",
      "Epoch 14/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6243 - val_loss: 0.5917\n",
      "Epoch 15/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6132 - val_loss: 0.5826\n",
      "Epoch 16/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6035 - val_loss: 0.5729\n",
      "Epoch 17/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5874 - val_loss: 0.5627\n",
      "Epoch 18/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5983 - val_loss: 0.5526\n",
      "Epoch 19/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5855 - val_loss: 0.5410\n",
      "Epoch 20/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5695 - val_loss: 0.5273\n",
      "Epoch 21/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5471 - val_loss: 0.5119\n",
      "Epoch 22/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5517 - val_loss: 0.4947\n",
      "Epoch 23/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5352 - val_loss: 0.4762\n",
      "Epoch 24/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5271 - val_loss: 0.4576\n",
      "Epoch 25/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5389 - val_loss: 0.4408\n",
      "Epoch 26/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4869 - val_loss: 0.4243\n",
      "Epoch 27/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4735 - val_loss: 0.4064\n",
      "Epoch 28/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4832 - val_loss: 0.3886\n",
      "Epoch 29/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4690 - val_loss: 0.3729\n",
      "Epoch 30/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4414 - val_loss: 0.3585\n",
      "Epoch 31/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4158 - val_loss: 0.3448\n",
      "Epoch 32/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4288 - val_loss: 0.3324\n",
      "Epoch 33/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4231 - val_loss: 0.3219\n",
      "Epoch 34/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3780 - val_loss: 0.3129\n",
      "Epoch 35/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3840 - val_loss: 0.3051\n",
      "Epoch 36/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3646 - val_loss: 0.2962\n",
      "Epoch 37/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3701 - val_loss: 0.2858\n",
      "Epoch 38/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3985 - val_loss: 0.2778\n",
      "Epoch 39/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3631 - val_loss: 0.2712\n",
      "Epoch 40/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3250 - val_loss: 0.2648\n",
      "Epoch 41/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3847 - val_loss: 0.2598\n",
      "Epoch 42/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3405 - val_loss: 0.2554\n",
      "Epoch 43/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3331 - val_loss: 0.2489\n",
      "Epoch 44/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3372 - val_loss: 0.2394\n",
      "Epoch 45/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3094 - val_loss: 0.2309\n",
      "Epoch 46/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3408 - val_loss: 0.2254\n",
      "Epoch 47/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3082 - val_loss: 0.2208\n",
      "Epoch 48/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3266 - val_loss: 0.2157\n",
      "Epoch 49/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2980 - val_loss: 0.2110\n",
      "Epoch 50/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2995 - val_loss: 0.2070\n",
      "Epoch 51/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3127 - val_loss: 0.2045\n",
      "Epoch 52/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2920 - val_loss: 0.2031\n",
      "Epoch 53/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2794 - val_loss: 0.1991\n",
      "Epoch 54/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2846 - val_loss: 0.1939\n",
      "Epoch 55/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2682 - val_loss: 0.1877\n",
      "Epoch 56/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2671 - val_loss: 0.1846\n",
      "Epoch 57/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2796 - val_loss: 0.1810\n",
      "Epoch 58/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2657 - val_loss: 0.1778\n",
      "Epoch 59/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2650 - val_loss: 0.1791\n",
      "Epoch 60/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3032 - val_loss: 0.1811\n",
      "Epoch 61/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2610 - val_loss: 0.1805\n",
      "Epoch 62/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2432 - val_loss: 0.1770\n",
      "Epoch 63/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2458 - val_loss: 0.1681\n",
      "Epoch 64/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2931 - val_loss: 0.1634\n",
      "Epoch 65/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2558 - val_loss: 0.1619\n",
      "Epoch 66/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2584 - val_loss: 0.1618\n",
      "Epoch 67/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2572 - val_loss: 0.1613\n",
      "Epoch 68/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2601 - val_loss: 0.1590\n",
      "Epoch 69/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2471 - val_loss: 0.1557\n",
      "Epoch 70/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2353 - val_loss: 0.1514\n",
      "Epoch 71/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2710 - val_loss: 0.1499\n",
      "Epoch 72/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2596 - val_loss: 0.1496\n",
      "Epoch 73/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2275 - val_loss: 0.1499\n",
      "Epoch 74/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2582 - val_loss: 0.1523\n",
      "Epoch 75/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2090 - val_loss: 0.1531\n",
      "Epoch 76/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2444 - val_loss: 0.1529\n",
      "Epoch 77/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2331 - val_loss: 0.1508\n",
      "Epoch 78/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2422 - val_loss: 0.1440\n",
      "Epoch 79/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2249 - val_loss: 0.1400\n",
      "Epoch 80/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2100 - val_loss: 0.1376\n",
      "Epoch 81/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2461 - val_loss: 0.1375\n",
      "Epoch 82/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1983 - val_loss: 0.1377\n",
      "Epoch 83/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1867 - val_loss: 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2288 - val_loss: 0.1423\n",
      "Epoch 85/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2166 - val_loss: 0.1400\n",
      "Epoch 86/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1944 - val_loss: 0.1342\n",
      "Epoch 87/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1852 - val_loss: 0.1303\n",
      "Epoch 88/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1994 - val_loss: 0.1313\n",
      "Epoch 89/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2075 - val_loss: 0.1315\n",
      "Epoch 90/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2080 - val_loss: 0.1297\n",
      "Epoch 91/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1751 - val_loss: 0.1268\n",
      "Epoch 92/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2074 - val_loss: 0.1251\n",
      "Epoch 93/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2350 - val_loss: 0.1240\n",
      "Epoch 94/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2011 - val_loss: 0.1230\n",
      "Epoch 95/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1824 - val_loss: 0.1228\n",
      "Epoch 96/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1673 - val_loss: 0.1238\n",
      "Epoch 97/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1711 - val_loss: 0.1289\n",
      "Epoch 98/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1822 - val_loss: 0.1294\n",
      "Epoch 99/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1833 - val_loss: 0.1220\n",
      "Epoch 100/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1793 - val_loss: 0.1172\n",
      "Epoch 101/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1834 - val_loss: 0.1158\n",
      "Epoch 102/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1599 - val_loss: 0.1163\n",
      "Epoch 103/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1842 - val_loss: 0.1231\n",
      "Epoch 104/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1577 - val_loss: 0.1268\n",
      "Epoch 105/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2026 - val_loss: 0.1237\n",
      "Epoch 106/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1747 - val_loss: 0.1175\n",
      "Epoch 107/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1690 - val_loss: 0.1148\n",
      "Epoch 108/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1875 - val_loss: 0.1159\n",
      "Epoch 109/600\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1797 - val_loss: 0.1166\n",
      "Epoch 110/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1536 - val_loss: 0.1170\n",
      "Epoch 111/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1583 - val_loss: 0.1166\n",
      "Epoch 112/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1582 - val_loss: 0.1133\n",
      "Epoch 113/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1774 - val_loss: 0.1107\n",
      "Epoch 114/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1450 - val_loss: 0.1101\n",
      "Epoch 115/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1565 - val_loss: 0.1098\n",
      "Epoch 116/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1808 - val_loss: 0.1095\n",
      "Epoch 117/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1703 - val_loss: 0.1100\n",
      "Epoch 118/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1548 - val_loss: 0.1077\n",
      "Epoch 119/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1517 - val_loss: 0.1062\n",
      "Epoch 120/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1518 - val_loss: 0.1057\n",
      "Epoch 121/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1752 - val_loss: 0.1049\n",
      "Epoch 122/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1514 - val_loss: 0.1052\n",
      "Epoch 123/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1681 - val_loss: 0.1065\n",
      "Epoch 124/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1378 - val_loss: 0.1075\n",
      "Epoch 125/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1590 - val_loss: 0.1080\n",
      "Epoch 126/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1303 - val_loss: 0.1087\n",
      "Epoch 127/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1548 - val_loss: 0.1085\n",
      "Epoch 128/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1347 - val_loss: 0.1076\n",
      "Epoch 129/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1579 - val_loss: 0.1082\n",
      "Epoch 130/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1445 - val_loss: 0.1121\n",
      "Epoch 131/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1490 - val_loss: 0.1125\n",
      "Epoch 132/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1365 - val_loss: 0.1083\n",
      "Epoch 133/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1249 - val_loss: 0.1038\n",
      "Epoch 134/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1204 - val_loss: 0.1028\n",
      "Epoch 135/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1273 - val_loss: 0.1037\n",
      "Epoch 136/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1310 - val_loss: 0.1041\n",
      "Epoch 137/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1306 - val_loss: 0.1025\n",
      "Epoch 138/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1259 - val_loss: 0.1008\n",
      "Epoch 139/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1362 - val_loss: 0.1002\n",
      "Epoch 140/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0996 - val_loss: 0.0996\n",
      "Epoch 141/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1364 - val_loss: 0.1015\n",
      "Epoch 142/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1417 - val_loss: 0.1041\n",
      "Epoch 143/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1190 - val_loss: 0.1025\n",
      "Epoch 144/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1494 - val_loss: 0.1015\n",
      "Epoch 145/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1282 - val_loss: 0.0997\n",
      "Epoch 146/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1411 - val_loss: 0.0989\n",
      "Epoch 147/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1248 - val_loss: 0.0984\n",
      "Epoch 148/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1314 - val_loss: 0.0985\n",
      "Epoch 149/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1134 - val_loss: 0.0994\n",
      "Epoch 150/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1351 - val_loss: 0.1010\n",
      "Epoch 151/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1349 - val_loss: 0.1023\n",
      "Epoch 152/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1159 - val_loss: 0.1018\n",
      "Epoch 153/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1175 - val_loss: 0.1036\n",
      "Epoch 154/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1066 - val_loss: 0.1015\n",
      "Epoch 155/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1457 - val_loss: 0.0996\n",
      "Epoch 156/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1102 - val_loss: 0.0973\n",
      "Epoch 157/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1092 - val_loss: 0.0964\n",
      "Epoch 158/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1101 - val_loss: 0.0971\n",
      "Epoch 159/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0918 - val_loss: 0.0976\n",
      "Epoch 160/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1328 - val_loss: 0.0987\n",
      "Epoch 161/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1314 - val_loss: 0.0987\n",
      "Epoch 162/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1335 - val_loss: 0.1009\n",
      "Epoch 163/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1179 - val_loss: 0.1021\n",
      "Epoch 164/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1111 - val_loss: 0.1001\n",
      "Epoch 165/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1170 - val_loss: 0.0997\n",
      "Epoch 166/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1274 - val_loss: 0.0993\n",
      "Epoch 167/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1239 - val_loss: 0.1005\n",
      "Epoch 168/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1119 - val_loss: 0.1022\n",
      "Epoch 169/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1013 - val_loss: 0.1037\n",
      "Epoch 170/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1134 - val_loss: 0.1030\n",
      "Epoch 171/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1172 - val_loss: 0.0979\n",
      "Epoch 172/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1090 - val_loss: 0.0951\n",
      "Epoch 173/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1211 - val_loss: 0.0949\n",
      "Epoch 174/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0994 - val_loss: 0.0926\n",
      "Epoch 175/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1183 - val_loss: 0.0921\n",
      "Epoch 176/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1248 - val_loss: 0.0943\n",
      "Epoch 177/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0920 - val_loss: 0.0963\n",
      "Epoch 178/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1183 - val_loss: 0.0960\n",
      "Epoch 179/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0996 - val_loss: 0.0940\n",
      "Epoch 180/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1101 - val_loss: 0.0932\n",
      "Epoch 181/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1022 - val_loss: 0.0927\n",
      "Epoch 182/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1131 - val_loss: 0.0932\n",
      "Epoch 183/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1249 - val_loss: 0.0954\n",
      "Epoch 184/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1065 - val_loss: 0.0961\n",
      "Epoch 185/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1104 - val_loss: 0.0967\n",
      "Epoch 186/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0843 - val_loss: 0.0947\n",
      "Epoch 187/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1068 - val_loss: 0.0939\n",
      "Epoch 188/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1163 - val_loss: 0.0941\n",
      "Epoch 189/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1193 - val_loss: 0.0966\n",
      "Epoch 190/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1068 - val_loss: 0.1007\n",
      "Epoch 191/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1125 - val_loss: 0.1003\n",
      "Epoch 192/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 193/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1036 - val_loss: 0.0979\n",
      "Epoch 194/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1058 - val_loss: 0.0974\n",
      "Epoch 195/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1178 - val_loss: 0.0977\n",
      "Epoch 196/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1182 - val_loss: 0.1002\n",
      "Epoch 197/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1031 - val_loss: 0.0999\n",
      "Epoch 198/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1075 - val_loss: 0.0957\n",
      "Epoch 199/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0976 - val_loss: 0.0931\n",
      "Epoch 200/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 201/600\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1133 - val_loss: 0.0928\n",
      "Epoch 202/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0857 - val_loss: 0.0934\n",
      "Epoch 203/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0986 - val_loss: 0.0930\n",
      "Epoch 204/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1044 - val_loss: 0.0939\n",
      "Epoch 205/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1000 - val_loss: 0.0954\n",
      "Epoch 206/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0998 - val_loss: 0.1005\n",
      "Epoch 207/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1442 - val_loss: 0.1010\n",
      "Epoch 208/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1064 - val_loss: 0.0962\n",
      "Epoch 209/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0770 - val_loss: 0.0913\n",
      "Epoch 210/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0986 - val_loss: 0.0893\n",
      "Epoch 211/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0866 - val_loss: 0.0894\n",
      "Epoch 212/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1090 - val_loss: 0.0911\n",
      "Epoch 213/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1081 - val_loss: 0.0923\n",
      "Epoch 214/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0958 - val_loss: 0.0907\n",
      "Epoch 215/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1155 - val_loss: 0.0901\n",
      "Epoch 216/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0975 - val_loss: 0.0902\n",
      "Epoch 217/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0879 - val_loss: 0.0919\n",
      "Epoch 218/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0901 - val_loss: 0.0964\n",
      "Epoch 219/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1078 - val_loss: 0.0985\n",
      "Epoch 220/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0915 - val_loss: 0.1011\n",
      "Epoch 221/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1014 - val_loss: 0.0952\n",
      "Epoch 222/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0945 - val_loss: 0.0923\n",
      "Epoch 223/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0871 - val_loss: 0.0901\n",
      "Epoch 224/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0866 - val_loss: 0.0892\n",
      "Epoch 225/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0906 - val_loss: 0.0921\n",
      "Epoch 226/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1193 - val_loss: 0.0996\n",
      "Epoch 227/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0957 - val_loss: 0.1013\n",
      "Epoch 228/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1150 - val_loss: 0.0998\n",
      "Epoch 229/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0882 - val_loss: 0.0962\n",
      "Epoch 230/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0950 - val_loss: 0.0935\n",
      "Epoch 231/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0729 - val_loss: 0.0928\n",
      "Epoch 232/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0741 - val_loss: 0.0926\n",
      "Epoch 233/600\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0901 - val_loss: 0.0953\n",
      "Epoch 234/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0922 - val_loss: 0.0994\n",
      "Epoch 235/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0755 - val_loss: 0.0956\n",
      "Epoch 236/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0933 - val_loss: 0.0936\n",
      "Epoch 237/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0782 - val_loss: 0.0910\n",
      "Epoch 238/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0832 - val_loss: 0.0903\n",
      "Epoch 239/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0835 - val_loss: 0.0903\n",
      "Epoch 240/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1062 - val_loss: 0.0915\n",
      "Epoch 241/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1000 - val_loss: 0.0936\n",
      "Epoch 242/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0788 - val_loss: 0.0987\n",
      "Epoch 243/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0891 - val_loss: 0.0995\n",
      "Epoch 244/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0973 - val_loss: 0.1036\n",
      "Epoch 245/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0942 - val_loss: 0.1016\n",
      "Epoch 246/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0802 - val_loss: 0.0954\n",
      "Epoch 247/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0867 - val_loss: 0.0917\n",
      "Epoch 248/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0921 - val_loss: 0.0918\n",
      "Epoch 249/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1008 - val_loss: 0.0919\n",
      "Epoch 00249: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf28d1d310>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,batch_size=128,\n",
    "         validation_data=(X_test,y_test),epochs=600,\n",
    "          callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(data=model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "This is a better behavior than previous one\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)\n",
    "test_predictions=pd.Series(predictions.reshape(143,))\n",
    "pred_df=pd.DataFrame(y_test,columns=[\"True Test Y\"])\n",
    "pred_df=pd.concat([pred_df,test_predictions],axis=1)\n",
    "pred_df.columns=[\"True Test Y\",\"Model Prediction\"]\n",
    "pred_df[\"Model Prediction\"]=pred_df[\"Model Prediction\"].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Test Y</th>\n",
       "      <th>Model Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Test Y  Model Prediction\n",
       "0              1                 1\n",
       "1              1                 1\n",
       "2              1                 1\n",
       "3              0                 0\n",
       "4              1                 1\n",
       "..           ...               ...\n",
       "138            0                 0\n",
       "139            1                 1\n",
       "140            0                 0\n",
       "141            1                 1\n",
       "142            0                 0\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.04288639296961526\n",
      "MSE: 0.018324767562135948\n",
      "RMSE: 0.13536900517524664\n",
      "VarScore: 0.9227699480731295\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', mean_absolute_error(y_test, predictions))  \n",
    "print('MSE:', mean_squared_error(y_test, predictions))  \n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('VarScore:',explained_variance_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predict_class=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        55\n",
      "           1       0.99      0.98      0.98        88\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first I didn't use dropout and when I created the dataframe to compare true value and predictions, it showed me only 2/143 data were wrong. \n",
    "\n",
    "After I used dropout, the accuracy inceased slightly. However I still feel like it is not fully learned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
